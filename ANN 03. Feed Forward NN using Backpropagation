import numpy as np
import matplotlib.pyplot as plt

# Sigmoid activation and derivative
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(output):
    return output * (1 - output)

# XOR Dataset
X = np.array([[0, 0],
              [0, 1],
              [1, 0],
              [1, 1]])
y = np.array([[0], [1], [1], [0]])

# Initialize hyperparameters
np.random.seed(1)
input_size = 2
hidden_size = 2
output_size = 1
learning_rate = 0.1
epochs = 10000

# Initialize weights and biases
weights_input_hidden = np.random.rand(input_size, hidden_size)
weights_hidden_output = np.random.rand(hidden_size, output_size)
bias_hidden = np.zeros((1, hidden_size))
bias_output = np.zeros((1, output_size))

# Store losses for plotting
losses = []

# Training loop
for epoch in range(epochs):
    # === Forward Propagation ===
    hidden_input = np.dot(X, weights_input_hidden) + bias_hidden
    hidden_output = sigmoid(hidden_input)

    final_input = np.dot(hidden_output, weights_hidden_output) + bias_output
    predicted_output = sigmoid(final_input)

    # === Error and Loss ===
    error = y - predicted_output
    loss = np.mean(np.square(error))  # Mean Squared Error
    losses.append(loss)

    # === Backpropagation ===
    d_output = error * sigmoid_derivative(predicted_output)
    d_hidden = d_output.dot(weights_hidden_output.T) * sigmoid_derivative(hidden_output)

    # === Weight and Bias Updates ===
    weights_hidden_output += hidden_output.T.dot(d_output) * learning_rate
    weights_input_hidden += X.T.dot(d_hidden) * learning_rate
    bias_output += np.sum(d_output, axis=0, keepdims=True) * learning_rate
    bias_hidden += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate

    if epoch % 1000 == 0:
        print(f"Epoch {epoch}, Loss: {loss:.5f}")

# Final prediction
print("\nFinal predictions after training:")
print(np.round(predicted_output))

# === Plotting Loss Curve ===
plt.plot(losses)
plt.title("Training Loss Curve")
plt.xlabel("Epoch")
plt.ylabel("Loss (MSE)")
plt.grid(True)
plt.show()


'''
An epoch in machine learning refers to one complete pass through the entire training dataset. In the context of training a neural network, during each epoch, the following steps typically occur:

Forward Propagation: The network makes predictions (outputs) based on the current weights and biases.

Loss Calculation: The error or loss is computed by comparing the predictions to the actual labels.

Backward Propagation: The gradients of the loss with respect to the weights and biases are calculated using backpropagation.

Parameter Update: The weights and biases are adjusted using the computed gradients (usually with gradient descent or a variant).

So, an epoch is one cycle through all these steps for the entire training dataset. The more epochs you run, the better the model can learn from the data, though after a certain number of epochs, the model might start to overfit, meaning it starts memorizing the training data rather than generalizing to new data.

In your code, the model is set to train for 10,000 epochs:

python
Copy
Edit
num_epochs = 10000
This means the training process will go through the dataset 10,000 times. The model's performance (measured by loss) is typically monitored during these epochs to ensure it is improving and to decide when to stop the training process.

Why Choose Multiple Epochs?
Underfitting: If the number of epochs is too small, the model may not learn enough from the data and may underperform (underfitting).

Overfitting: If the number of epochs is too large, the model might overfit the training data, meaning it will perform well on the training set but poorly on unseen data.

You can monitor the loss over epochs to decide if the training is progressing well, and in practice, the training can be stopped early if the loss starts to stabilize or increase (i.e., when overfitting occurs).

'''
